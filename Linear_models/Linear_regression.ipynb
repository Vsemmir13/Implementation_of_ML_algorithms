{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016ae52b",
   "metadata": {},
   "source": [
    "# Линейная регрессия (Linear Regression)\n",
    "Метод машинного обучения, в котором ищется отношение зависимой переменной от одной или нескольких независимых переменных (регрессоров) посредством линейной функции. Стохастический градиентный спуск основан на функции MSE. Также модель дополнена регуляризацией, чтобы бороться со сложностью модели.\n",
    "\n",
    "Реализованы методы:\n",
    "- fit для обучения модели (со стохастическим градиентным спуском)\n",
    "- predict для предсказания таргетов\n",
    "- _init_ - конструктор\n",
    "- calculate_loss - подсчитывает функцию потерь c учетом регуляризации\n",
    "- get_best_score - возвращает последнее значение метрики (т.е. уже полностью обученной модели)\n",
    "- calculate_metric - подсчитывает метрики\n",
    "- calculate_regularization_grad - подсчитывает производную для регуляризации\n",
    "\n",
    "Дополнительно реализован подсчет метрик:\n",
    "- mae\n",
    "- mse\n",
    "- rmse\n",
    "- mape\n",
    "- r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "247eecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89914654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg():\n",
    "    \n",
    "    def __init__(self, n_iter=100, learning_rate=0.1, weights=False, metric=None, reg=None, l1_coef=0, l2_coef=0,\n",
    "                 sgd_sample=None, random_state=42):\n",
    "        '''\n",
    "        Input:\n",
    "        n_iter: the number of steps of gradient descent (default = 100)\n",
    "        learning_rate: gradient descent learning rate coefficient or lambda function (default = 0.1)\n",
    "        weights: array of model weights (default = empty)\n",
    "        metric: string, name of the metric from array ['mae', 'mse', 'rmse', 'mape', 'r2'], (default = None)\n",
    "        reg: string, regularization for model, name from ['l1', 'l2', 'elasticnet'], (default = None)\n",
    "        l1_coef: value between 0.0 and 1.0 for L1_reg (default = 0)\n",
    "        l2_coef: value between 0.0 and 1.0 for L2_reg (default = 0)\n",
    "        sgd_sample: the number of samples that will be used in each iteration of the training. \n",
    "        It can accept either integers or fractions from 0.0 to 1.0.\n",
    "        random_state: integer\n",
    "        '''\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.metric_values = []\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def __str__(self):\n",
    "        '''\n",
    "        Output: \n",
    "        string - info about class parameters\n",
    "        '''\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "    \n",
    "    def fit(self, X, y, verbose):\n",
    "        '''\n",
    "        Input:\n",
    "        X: DataFrame of features\n",
    "        y: Series of targets\n",
    "        verbose (int): indicates which iteration to output the log (default = False)\n",
    "        '''\n",
    "        random.seed(self.random_state)\n",
    "        # Complete the passed feature matrix with a single column on the left.\n",
    "        X = pd.concat([pd.Series(1, index=X.index), X], axis=1)\n",
    "        self.weights = np.ones(X.shape[1])\n",
    "        \n",
    "        if verbose and not(self.metric is None):\n",
    "            print(f\"start | loss: {self.calculate_loss(X, y)} | {self.metric}: {self.calculate_metric(X, y)}\")\n",
    "\n",
    "        for i in range(1, self.n_iter + 1):\n",
    "            \n",
    "            # Check lambda function\n",
    "            if callable(self.learning_rate):\n",
    "                lr = self.learning_rate(i)\n",
    "            else:\n",
    "                lr = self.learning_rate\n",
    "            \n",
    "            # Form the sequence numbers of the lines that should be selected for Stochastic gradient descent\n",
    "            if self.sgd_sample is not None:\n",
    "                if isinstance(self.sgd_sample, int):\n",
    "                    sample_size = self.sgd_sample\n",
    "                elif 0 < self.sgd_sample < 1:\n",
    "                    sample_size = int(self.sgd_sample * X.shape[0])\n",
    "                \n",
    "                sample_rows_idx = random.sample(range(X.shape[0]), sample_size)\n",
    "                X_sample = X.iloc[sample_rows_idx]\n",
    "                y_sample = y.iloc[sample_rows_idx]\n",
    "            else:\n",
    "                X_sample = X\n",
    "                y_sample = y\n",
    "\n",
    "            y_pred = np.dot(X_sample, self.weights)\n",
    "            \n",
    "            # Calculate the gradient based on MSE and regularization\n",
    "            gradient = 2 * np.dot(y_pred - y_sample, X_sample) / X_sample.shape[0] + self.calculate_regularization_grad()\n",
    "                        \n",
    "            # Make a step with the size of the lr in the opposite direction from the gradient\n",
    "            self.weights -= lr * gradient\n",
    "            \n",
    "            if verbose and i % verbose == 0 and not(self.metric is None):\n",
    "                print(f\"start | loss: {self.calculate_loss(X, y)} | {self.metric}: {self.calculate_metric(X, y)}\")\n",
    "        \n",
    "        if self.metric:\n",
    "            self.metric_values.append(self.calculate_metric(X, y))\n",
    "    \n",
    "    def calculate_regularization_grad(self):\n",
    "        '''\n",
    "        Output:\n",
    "        float - regularization gradient\n",
    "        '''\n",
    "        if self.reg == \"l1\":\n",
    "            return self.l1_coef * np.sign(self.weights)      \n",
    "        if self.reg == \"l2\":\n",
    "            return 2 * self.l2_coef * self.weights    \n",
    "        if self.reg == \"elasticnet\":\n",
    "            return self.l1_coef * np.sign(self.weights) + 2 * self.l2_coef * self.weights\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    def calculate_loss(self, X, y):\n",
    "        '''\n",
    "        Input:\n",
    "        X: DataFrame of features\n",
    "        y: Series of targets\n",
    "        Output: MSE and regularization -> float\n",
    "        '''\n",
    "        y_pred = np.dot(X, self.weights)\n",
    "        loss = np.mean((y_pred - y) ** 2)\n",
    "        if self.reg == \"l1\":\n",
    "            reg_loss = self.l1_coef *  np.sum(np.abs(self.weights)) \n",
    "        elif self.reg == \"l2\":\n",
    "            reg_loss = self.l2_coef * np.sum(self.weights ** 2)\n",
    "        elif self.reg == \"elasticnet\":\n",
    "            reg_loss = self.l1_coef *  np.sum(np.abs(self.weights)) + self.l2_coef * np.sum(self.weights ** 2)\n",
    "        else:\n",
    "            reg_loss = 0\n",
    "        loss += reg_loss\n",
    "        return reg_loss\n",
    "    \n",
    "    def get_coef(self):\n",
    "        '''\n",
    "        Output:\n",
    "        np.array of weights without first \n",
    "        '''\n",
    "        return self.weights[1:]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Input:\n",
    "        X: DataFrame of features\n",
    "        Output:\n",
    "        y_pred: array of prediction\n",
    "        '''\n",
    "        X = pd.concat([pd.Series(1, index=X.index), X], axis=1)\n",
    "        y_pred = np.dot(X, self.weights)\n",
    "        return y_pred\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        return self.metric_values[-1] if self.metric_values else None\n",
    "    \n",
    "    def calculate_metric(self, X, y):\n",
    "        y_pred = np.dot(X, self.weights)\n",
    "        \n",
    "        if self.metric == 'mae':\n",
    "            return np.mean(np.abs(y_pred - y))\n",
    "        \n",
    "        elif self.metric == 'mse':\n",
    "            return np.mean((y_pred - y) ** 2)\n",
    "        \n",
    "        elif self.metric == 'rmse':\n",
    "            return np.sqrt(np.mean((y_pred - y) ** 2))\n",
    "        \n",
    "        elif self.metric == 'mape':\n",
    "            return np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "        \n",
    "        elif self.metric == 'r2':\n",
    "            ss_res = np.sum((y - y_pred) ** 2)\n",
    "            ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "            return 1 - (ss_res / ss_tot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b573383",
   "metadata": {},
   "source": [
    "## Протестируем модель\n",
    "\n",
    "Входные данные: датасет с различными параметрами (сгенерированными посредством метода make_regression из scikit-learn)\n",
    "\n",
    "Выходные данные: возвращенные предсказания и MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3dac943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d42e7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 0.0 | mae: 112.80906582514544\n",
      "start | loss: 0.0 | mae: 0.008318875593259337\n",
      "start | loss: 0.0 | mae: 2.276170724027221e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.097254555204565e-11"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = MyLineReg(metric='mae', reg='elasticnet', sgd_sample=0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train, 50)\n",
    "y_pred = model.predict(X_test)\n",
    "np.mean((y_pred - y_test) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22daaca",
   "metadata": {},
   "source": [
    "Как ожидалось, наша модель работает корректно. Следовательно, алгоритм реализован верно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
